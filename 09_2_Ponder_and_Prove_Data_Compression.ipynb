{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_2_Ponder_and_Prove_Data_Compression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrettonSteiner/cse380-notebooks/blob/master/09_2_Ponder_and_Prove_Data_Compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rG4k7VvQ2WT"
      },
      "source": [
        "# Ponder and Prove Data Compression\n",
        "#### Due: Saturday, 6 March 2021, 11:59 pm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0WxE3IAQ2WU"
      },
      "source": [
        "# TODO Explore Huffman Trees and Huffman Codes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2vby9erSjOv"
      },
      "source": [
        "Your task is examine how to compress a *special piece of information* as compactly as possible, and **calculate various compression ratios**.\n",
        "\n",
        "Recall that the **compression ratio** of a variable-length encoding like Huffman encoding is the percentage $100(f - v)/f$, where $f$ is the number of bits per symbol of the smallest **fixed**-length encoding, and $v$ is the average number of bits per symbol with the variable-length encoding.\n",
        "\n",
        "For example, if there were 9 different symbols in a message, $f=4$ is the number of bits of the smallest fixed-length encoding, because $2^3 = 8$ (not enough for $9$) and $2^4 = 16$ (enough and to spare). If the variable-length encoding of the message had $v=3.12$, the compression ratio would be $100(4 - 3.12)/4 \\approx 22\\%$.\n",
        "\n",
        "Note that calculating the average number of bits per symbol is not strictly necessary. That's because an alternate and equivalent way is to calculate $100(ft - vt)/ft$, where $ft$ is the **total** number of bits encoded with the fixed encoding, and $vt$ is the **total** number of bits encoded with the variable-length encoding.\n",
        "\n",
        "The *special piece of information* to be compressed is a list of the first ten million primes. This is a list that starts\n",
        "\n",
        "|    |\n",
        "|----|\n",
        "|  2 |\n",
        "|  3 |\n",
        "|  5 |\n",
        "|  7 |\n",
        "| 11 |\n",
        "| 13 |\n",
        "| 17 |\n",
        "| 19 |\n",
        "| 23 |\n",
        "| 29 |\n",
        "\n",
        "  and ends\n",
        "\n",
        "|           |\n",
        "|-----------|\n",
        "| 179424551 |\n",
        "| 179424571 |\n",
        "| 179424577 |\n",
        "| 179424601 |\n",
        "| 179424611 |\n",
        "| 179424617 |\n",
        "| 179424629 |\n",
        "| 179424667 |\n",
        "| 179424671 |\n",
        "| 179424673 |\n",
        "\n",
        "As ASCII text stored in a file with one prime per line, the size of this data file is slightly over 89 megabytes. The goal is to compress this down to just over 5 megabytes (5589056 bytes, to be exact). That's a 94% compression ratio!\n",
        "\n",
        "Standard compression tools can only get about a 73% compression ratio for this ASCII data. A more clever approach is needed. Instead of compressing the list of prime numbers, compress a list of the *gaps* between them!\n",
        "\n",
        "It doesn't save much, just the unique (occurring only once) gap size of 1 between 2 and 3, but in the spirit of de Polignac's conjecture that every *even* number appears infinitely often as a gap between consecutive primes, just consider the even-sized gaps. The result will be a list that starts with 2 (the difference between 5 and 3), 2 (the difference between 7 and 5), 4 (the difference between 11 and 7), 2 (the difference between 13 and 11), 4 (the difference between 17 and 13), 2 (the difference between 19 and 17), 4 (the difference between 23 and 19), and 6 (the difference between 29 and 23).\n",
        "\n",
        "Generating this data is the first task. The algorithm for doing so is very straightforward:\n",
        "\n",
        "1. Find the gaps between consecutive odd primes.\n",
        "2. Store these gaps as a list of even numbers.\n",
        "\n",
        "Tabulating the results, the first ten gaps and the last ten gaps are as follows, where the numbers after the equals signs are the gaps to list:\n",
        "\n",
        "|                 |\n",
        "|-----------------|\n",
        "|  5  -   3  =  2 |\n",
        "|  7  -   5  =  2 |\n",
        "| 11  -   7  =  4 |\n",
        "| 13  -  11  =  2 |\n",
        "| 17  -  13  =  4 |\n",
        "| 19  -  17  =  2 |\n",
        "| 23  -  19  =  4 |\n",
        "| 29  -  23  =  6 |\n",
        "| 31  -  29  =  2 |\n",
        "| 37  -  31  =  6 |\n",
        "\n",
        "|                                |\n",
        "|--------------------------------|\n",
        "| 179424551  -  179424533  =  18 |\n",
        "| 179424571  -  179424551  =  20 |\n",
        "| 179424577  -  179424571  =   6 |\n",
        "| 179424601  -  179424577  =  24 |\n",
        "| 179424611  -  179424601  =  10 |\n",
        "| 179424617  -  179424611  =   6 |\n",
        "| 179424629  -  179424617  =  12 |\n",
        "| 179424667  -  179424629  =  38 |\n",
        "| 179424671  -  179424667  =   4 |\n",
        "| 179424673  -  179424671  =   2 |\n",
        "\n",
        "As a correctness check, see if your generated list of gaps has length 9999998.\n",
        "\n",
        "The next step is to count how many times each gap size occurs, so that for the Huffman encoding scheme, the larger the frequency of occurrence, the smaller the number of bits encoding that gap size.\n",
        "\n",
        "As a correctness check, here are the first ten and the last ten gap counts:\n",
        "\n",
        "|  Gap | Count   |\n",
        "|------|---------|\n",
        "|    2 |  738597 |\n",
        "|    4 |  738717 |\n",
        "|    6 | 1297540 |\n",
        "|    8 |  566151 |\n",
        "|   10 |  729808 |\n",
        "|   12 |  920661 |\n",
        "|   14 |  503524 |\n",
        "|   16 |  371677 |\n",
        "|   18 |  667734 |\n",
        "|   20 |  354267 |\n",
        "|      |         |\n",
        "|  190 |       1 |\n",
        "|  192 |       3 |\n",
        "|  194 |       1 |\n",
        "|  196 |       1 |\n",
        "|  198 |       6 |\n",
        "|  202 |       2 |\n",
        "|  204 |       3 |\n",
        "|  210 |       4 |\n",
        "|  220 |       1 |\n",
        "|  222 |       1 |\n",
        "\n",
        "Note two things from these partial gap counts:\n",
        "\n",
        "1. Small even numbers (< 100) are well represented, larger ones (< 1000) less so.\n",
        "2. Ten million primes aren't enough to have *every* even number represented; for example, 200, 206, 208, 212, 214, 216, and 218 do not appear even once.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CUIw8_k03JJ"
      },
      "source": [
        "# TODO Determine Exact Size of Data to be Compressed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB4sXf0X09Gv"
      },
      "source": [
        "Without actually doing it, imagine creating an ASCII file containing the first ten million primes, represented in decimal, one prime per line. Calculate the size of this file, so you can show an exceptional compression ratio from it (see below).\n",
        "\n",
        "Using a binary encoding instead of ASCII, each prime requires 32 bits (4 bytes), so the size of a binary file is easily determined.\n",
        "\n",
        "Using a fixed-width encoding of the gap counts, however, requires knowing how many different gap sizes there are, after which the calculation is straightforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbficvnenGmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d50e16b-5fe7-4235-a7cf-81c92a96ee63"
      },
      "source": [
        "!pip install pyprimesieve"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyprimesieve\n",
            "  Downloading https://files.pythonhosted.org/packages/71/65/df0f953cfda5aa6dba56bcbeac5707f544bf0ad5b649a6a7807c5e09966e/pyprimesieve-0.1.6.tar.gz\n",
            "Building wheels for collected packages: pyprimesieve\n",
            "  Building wheel for pyprimesieve (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyprimesieve: filename=pyprimesieve-0.1.6-cp37-cp37m-linux_x86_64.whl size=368927 sha256=df7ca4c1af6e2172e6af75fe701c39f6d6d70d8cd482e37b88c22fe241134c35\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/63/2b/a485079de882a375d28a4dc141386c76ea9a6aaad505f2198b\n",
            "Successfully built pyprimesieve\n",
            "Installing collected packages: pyprimesieve\n",
            "Successfully installed pyprimesieve-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWny0QFBmic4"
      },
      "source": [
        "import pyprimesieve\r\n",
        "\r\n",
        "# Thanks, Kyle!\r\n",
        "tmp = pyprimesieve.primes_nth(10000000)\r\n",
        "primes = pyprimesieve.primes(tmp+1)\r\n",
        "gaps = [*map(lambda i:primes[i]-primes[i-1],range(2,10000000))]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCpcKjlvmjv3"
      },
      "source": [
        "from math import log10, floor\r\n",
        "\r\n",
        "# get the number of digits in a certain number\r\n",
        "def get_num_digits_in_num(n):\r\n",
        "    return floor(log10(n))\r\n",
        "\r\n",
        "# make sure to calculate in the newline character\r\n",
        "def get_line_size(n):\r\n",
        "    return get_num_digits_in_num(n) + 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7HVhikfmlLn"
      },
      "source": [
        "total_size_in_digits = sum(map(lambda p: get_line_size(p), primes))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpAa9udxmmRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65699616-b776-46ef-b7f2-abd39448b3a0"
      },
      "source": [
        "total_size_in_bits = total_size_in_digits * 8\r\n",
        "print(\"File size in Megabytes:\", (total_size_in_digits + 10 ** 7) / 2 ** 20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File size in Megabytes: 89.15371894836426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HZChUyC09tJ"
      },
      "source": [
        "# TODO Use Functional Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7vG1XqY1CaV"
      },
      "source": [
        "You are encouraged to use the [anytree](https://pypi.org/project/anytree) Python library, which has a nice exporter by way of which you can graphically view trees. (You may recall using this in DM1, and thus know that **anytree** depends on [graphviz](https://graphviz.org), which you also used.)\n",
        "\n",
        "This library uses the object-oriented features of Python to create and visualize trees. You are encouraged to use the functional features of Python as much as possible, achieving your results not by using some existing third-party libraries for building Huffman Trees and Codes, but writing your own code as cleanly and elegantly as you can."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cySI_bddoUPZ",
        "outputId": "eea23d2a-2cc4-476f-ee3d-5f2f4316abe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install anytree"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anytree\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/65/be23d8c3ecd68d40541d49812cd94ed0f3ee37eb88669ca15df0e43daed1/anytree-2.8.0-py2.py3-none-any.whl (41kB)\n",
            "\r\u001b[K     |███████▉                        | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree) (1.15.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcRiHWGqnYag"
      },
      "source": [
        "from anytree import Node, RenderTree, PreOrderIter, Walker\r\n",
        "from anytree.util import leftsibling, rightsibling\r\n",
        "from anytree.exporter.dotexporter import DotExporter\r\n",
        "from collections import Counter\r\n",
        "from queue import PriorityQueue\r\n",
        "from math import ceil, floor, log\r\n",
        "from sympy import primerange\r\n",
        "\r\n",
        "def realprimes_up_to(n):\r\n",
        "  return list(primerange(4, n))\r\n",
        "\r\n",
        "def get_list_of_gaps(pl):\r\n",
        "  gaps_list = list(map(lambda i: pl[i] - pl[i - 1], range(1, len(pl))))\r\n",
        "  gaps_list = [2] + gaps_list # [2] for the gap between 3 and 5\r\n",
        "  return gaps_list\r\n",
        "\r\n",
        "class GapNode(Node):\r\n",
        "  def __lt__(self, other):\r\n",
        "    return self.count < other.count\r\n",
        "\r\n",
        "node_counter = 0\r\n",
        "def next_node_name():\r\n",
        "  global node_counter\r\n",
        "  name = 'gn' + str(node_counter)\r\n",
        "  node_counter += 1\r\n",
        "  return name\r\n",
        "\r\n",
        "def new_node(gp, ct):\r\n",
        "  return GapNode(next_node_name(), gap = gp, count = ct)\r\n",
        "\r\n",
        "def new_internal_node(left, right):\r\n",
        "  return GapNode(next_node_name(), children = [left, right],\r\n",
        "                 gap = 0, count = left.count + right.count)\r\n",
        "\r\n",
        "def make_huffman_tree(gaps_list):\r\n",
        "  gap_dict = Counter(gaps_list)\r\n",
        "  q = PriorityQueue()\r\n",
        "  for key, val in gap_dict.items():\r\n",
        "    q.put(new_node(key, val))\r\n",
        "\r\n",
        "  while q.qsize() > 1:\r\n",
        "    left = q.get()\r\n",
        "    right = q.get()\r\n",
        "    q.put(new_internal_node(left, right))\r\n",
        "\r\n",
        "  return q.get()\r\n",
        "\r\n",
        "def get_codes(root):\r\n",
        "  leaves = [node for node in PreOrderIter(root, filter_=lambda n: not n.children)]\r\n",
        "  codes = {}\r\n",
        "  w = Walker()\r\n",
        "  for leaf in leaves:\r\n",
        "    path = w.walk(leaf, root)[0]\r\n",
        "    code = ''\r\n",
        "    for node in path:\r\n",
        "      code = ('1' if leftsibling(node) else '0') + code\r\n",
        "    codes[leaf.gap] = tuple([code, leaf.count])\r\n",
        "  return codes\r\n",
        "\r\n",
        "def compression_ratio(f, v):\r\n",
        "  return 100 * (f - v) / f\r\n",
        "\r\n",
        "def get_encoded_size(codes):\r\n",
        "  return sum([len(code) * count for gap, (code, count) in codes.items()])\r\n",
        "\r\n",
        "def get_fixed_size(codes):\r\n",
        "  num_keys = len(codes)\r\n",
        "  num_bits_per_key = ceil(log(num_keys, 2))\r\n",
        "  return sum([num_bits_per_key * count for gap, (code, count) in codes.items()])\r\n",
        "\r\n",
        "def report(codes):\r\n",
        "  return compression_ratio(get_fixed_size(codes), get_encoded_size(codes))\r\n",
        "\r\n",
        "def test_up_to(primes, upper, results):\r\n",
        "  list_of_gaps = get_list_of_gaps(primes[:upper])\r\n",
        "  print(primes[:upper])\r\n",
        "  print(list_of_gaps)\r\n",
        "  root = make_huffman_tree(list_of_gaps)\r\n",
        "  print(RenderTree(root))\r\n",
        "  DotExporter(root).to_picture(f'gap-tree-{upper:02d}.png')\r\n",
        "  codes = get_codes(root)\r\n",
        "  print(upper, '-->', get_encoded_size(codes))\r\n",
        "  cr = round(report(codes))\r\n",
        "  results[upper - 1] = cr # adjust since upper is the number of primes, -1 to make it just odd primes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hMKmx7sqiyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986306ed-1bfd-4c4a-97fd-dbb357a149e0"
      },
      "source": [
        "tmp = pyprimesieve.primes_nth(10000000)\r\n",
        "primes = pyprimesieve.primes(tmp+1)\r\n",
        "gaps = [*map(lambda i:primes[i]-primes[i-1],range(2,10000000))]\r\n",
        "\r\n",
        "# Verify with the instructions above:\r\n",
        "print(len(primes))\r\n",
        "print(primes[:5])\r\n",
        "print(primes[-5:])\r\n",
        "print()\r\n",
        "print(len(gaps))\r\n",
        "print(gaps[:5])\r\n",
        "print(gaps[-5:])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000000\n",
            "[2, 3, 5, 7, 11]\n",
            "[179424617, 179424629, 179424667, 179424671, 179424673]\n",
            "\n",
            "9999998\n",
            "[2, 2, 4, 2, 4]\n",
            "[6, 12, 38, 4, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojz6p1HBrYGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5ae327-f1f3-418a-f93e-7685d2a9bdea"
      },
      "source": [
        "treeRoot = make_huffman_tree(gaps)\r\n",
        "codes = get_codes(treeRoot)\r\n",
        "codes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: ('1100', 738597),\n",
              " 4: ('1101', 738717),\n",
              " 6: ('100', 1297540),\n",
              " 8: ('0101', 566151),\n",
              " 10: ('1011', 729808),\n",
              " 12: ('000', 920661),\n",
              " 14: ('0100', 503524),\n",
              " 16: ('11100', 371677),\n",
              " 18: ('0111', 667734),\n",
              " 20: ('10101', 354267),\n",
              " 22: ('01101', 307230),\n",
              " 24: ('0010', 453215),\n",
              " 26: ('111110', 211203),\n",
              " 28: ('111111', 229177),\n",
              " 30: ('11101', 398713),\n",
              " 32: ('001110', 123123),\n",
              " 34: ('011000', 129043),\n",
              " 36: ('111101', 206722),\n",
              " 38: ('1010011', 94682),\n",
              " 40: ('001100', 111546),\n",
              " 42: ('101000', 159956),\n",
              " 44: ('0011111', 64866),\n",
              " 46: ('11110010', 54931),\n",
              " 48: ('1010010', 93693),\n",
              " 50: ('11110001', 52183),\n",
              " 52: ('01100111', 38800),\n",
              " 54: ('0011110', 64157),\n",
              " 56: ('01100100', 32224),\n",
              " 58: ('00110101', 27985),\n",
              " 60: ('11110011', 55305),\n",
              " 62: ('011001010', 16763),\n",
              " 64: ('011001100', 17374),\n",
              " 66: ('00110110', 30960),\n",
              " 68: ('1111000010', 12368),\n",
              " 70: ('011001101', 17475),\n",
              " 72: ('011001011', 17255),\n",
              " 74: ('0011011111', 8540),\n",
              " 76: ('0011011101', 7253),\n",
              " 78: ('001101000', 13758),\n",
              " 80: ('11110000111', 6760),\n",
              " 82: ('11110000001', 4791),\n",
              " 84: ('1111000001', 9818),\n",
              " 86: ('00110100100', 3411),\n",
              " 88: ('00110100101', 3454),\n",
              " 90: ('0011010011', 7056),\n",
              " 92: ('111100000000', 2259),\n",
              " 94: ('001101111010', 2058),\n",
              " 96: ('00110111000', 3544),\n",
              " 98: ('001101110011', 1831),\n",
              " 100: ('001101111001', 1923),\n",
              " 102: ('111100000001', 2374),\n",
              " 104: ('1111000011000', 1168),\n",
              " 106: ('0011011100101', 933),\n",
              " 108: ('1111000011011', 1634),\n",
              " 110: ('0011011110000', 941),\n",
              " 112: ('11110000110100', 711),\n",
              " 114: ('0011011110111', 1125),\n",
              " 116: ('00110111001000', 439),\n",
              " 118: ('111100001101011', 433),\n",
              " 120: ('0011011110001', 948),\n",
              " 122: ('001101111011011', 287),\n",
              " 124: ('111100001100110', 318),\n",
              " 126: ('00110111101100', 533),\n",
              " 128: ('1111000011001110', 183),\n",
              " 130: ('001101110010010', 211),\n",
              " 132: ('111100001100100', 301),\n",
              " 134: ('0011011110110101', 128),\n",
              " 136: ('11110000110101001', 100),\n",
              " 138: ('1111000011010101', 210),\n",
              " 140: ('1111000011001010', 140),\n",
              " 142: ('11110000110011110', 90),\n",
              " 144: ('0011011100100111', 123),\n",
              " 146: ('111100001101010000', 46),\n",
              " 148: ('00110111101101001', 67),\n",
              " 150: ('11110000110011111', 94),\n",
              " 152: ('00110111001001100', 52),\n",
              " 154: ('111100001100101110', 43),\n",
              " 156: ('00110111101101000', 57),\n",
              " 158: ('1111000011001011001', 19),\n",
              " 160: ('001101110010011010', 27),\n",
              " 162: ('1111000011010100011', 27),\n",
              " 164: ('1111000011001011011', 20),\n",
              " 166: ('11110000110010110100', 9),\n",
              " 168: ('1111000011010100010', 25),\n",
              " 170: ('1111000011001011000', 18),\n",
              " 172: ('001101110010011011110', 4),\n",
              " 174: ('11110000110010110101', 10),\n",
              " 176: ('11110000110010111110', 11),\n",
              " 178: ('11110000110010111111', 12),\n",
              " 180: ('11110000110010111100', 10),\n",
              " 182: ('111100001100101111010', 5),\n",
              " 184: ('001101110010011011111', 4),\n",
              " 186: ('1111000011001011110111', 3),\n",
              " 188: ('00110111001001101110000', 1),\n",
              " 190: ('00110111001001101110010', 1),\n",
              " 192: ('001101110010011011010', 3),\n",
              " 194: ('00110111001001101110001', 1),\n",
              " 196: ('00110111001001101110011', 1),\n",
              " 198: ('00110111001001101100', 6),\n",
              " 202: ('0011011100100110110110', 2),\n",
              " 204: ('1111000011001011110110', 3),\n",
              " 210: ('001101110010011011101', 4),\n",
              " 220: ('00110111001001101101110', 1),\n",
              " 222: ('00110111001001101101111', 1)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRc_rb7cr_U7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcdee85-f75d-4ba0-c03b-14c20a7fd3da"
      },
      "source": [
        "fixed = get_fixed_size(codes)\r\n",
        "encoded = get_encoded_size(codes)\r\n",
        "print(fixed)\r\n",
        "print(encoded)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69999986\n",
            "44712373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUB4mD8u1DCa"
      },
      "source": [
        "# TODO Achieve Target Compression Ratios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vw71EqJ18eE"
      },
      "source": [
        "Your solution should correctly compute the following three compression ratios:\n",
        "\n",
        "| Ratio       | Value              |\n",
        "|-------------|--------------------|\n",
        "| From fixed  | 36.125168653605158 |\n",
        "| From binary |              86.03 |\n",
        "| From ASCII  |              94.02 | \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdk9Ut2asZ7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1a5118-97cc-477f-e4cf-32b776b2efc9"
      },
      "source": [
        "report(codes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.12516865360516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZmYZ9gS167G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2d31ae-c75d-4c60-fe5c-991a681d9fab"
      },
      "source": [
        "def get_bin_size(primes):\r\n",
        "  return 32 * len(primes)\r\n",
        "\r\n",
        "compression_ratio(get_bin_size(primes), get_encoded_size(codes))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.0273834375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0apLEJk32ibm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece2558b-69b2-4bf0-a210-ad4cfa86dfc2"
      },
      "source": [
        "def get_ascii_size(primes):\r\n",
        "  return sum([len(str(prime) + '\\n') * 8 for prime in primes])\r\n",
        "\r\n",
        "compression_ratio(get_ascii_size(primes), get_encoded_size(codes))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.02141572742846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81dbKwHenxnT"
      },
      "source": [
        "# TODO My Report on What I Did and What I Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BeiIern33B"
      },
      "source": [
        "## Fun\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElukRLoezyxd"
      },
      "source": [
        "I had fun creating the get_ascii_size function. While most other functions were figured out by my teammates or given to us through class, I figured out this one on my own. It felt great to get it right!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzOkZ3son-u9"
      },
      "source": [
        "## New"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-nYIdEUz4x5"
      },
      "source": [
        "I learned that Huffman Encoding may not always be a better solution for compressing data. If there are enough unique values to map to a Huffman tree, it will take more space than if we just used the true binary representation of the number instead. For example, to save the gap of 222 in binary it is this:\r\n",
        "\r\n",
        "11011110\r\n",
        "\r\n",
        "But in our Huffman Encoding it is this:\r\n",
        "\r\n",
        "00110111001001101101111\r\n",
        "\r\n",
        "So, even though it doesn't occur as often, it still ends up taking more than double the space a simple binary representation would have taken. This does make me wonder if a combination of the two approaches would be beneficial. That is, we would use the Huffman Encoding for all data points which end up having bit-strings shorter than its binary representation. And once the Huffman encodings get larger than the binary representations, we could just use the binary representations instead (as long as they don't include the same pattern of any of the Huffman codes within)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJHvoj6GokaZ"
      },
      "source": [
        "## Meaningful\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOxh3XFTz-6N"
      },
      "source": [
        "I believe I have achieved an understanding of how Huffman Trees work and how they can be used in data compression. This assignment has also helped me understand two other methods of compression, namely binary and ASCII compressions. In this case, both of those ended up being better at compression than the Huffman Tree, but that may not always be the case. I think this is something I can build upon later when it comes to data compression in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RBE03fhpNUG"
      },
      "source": [
        "## Other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-sXEeq60C3W"
      },
      "source": [
        "I know that we correctly calculated everything because we used much of the code which was provided for us to make the calculations, we came up with the desired results, and Brother Neff confirmed our solutions when we asked him.\r\n",
        "\r\n",
        "I worked with Claire Hocker, Daniel Strickland, and Hannah Parker on this assignment. Claire figured out how to calculate the binary size. Daniel and Hannah provided some insights that guided us along.\r\n",
        "\r\n",
        "I also made an interesting connection when learning about the Huffman Tree. No matter how many encodings I make with a Huffman Tree, there will never be any repeated patterns of smaller encodings within a larger encoding. This is ideal because we won't have to worry about storing the data with separators of any kind, thus further enhancing the compression ratio. This has led me to understand that it is impossible to get any repeated path patterns in a binary tree between the individual leaves. But, if I was considering the paths to branches too, then there would be repeated patterns since the children of that branch would include the path of their parent, too. Overall, this makes trees much more fascinating to me."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrk-8EmgW4NP"
      },
      "source": [
        "# TODO What is True?\n",
        "Click on each warranted checkbox to toggle it to True (or back to False). \n",
        "\n",
        "NOTE: *This only works in Colab. If you run it in some other Jupyter notebook client/server environment you may have to change False to True (or vice versa) manually.*\n",
        "\n",
        "This self-assessment is subject to revision by a grader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGAjzgVRXR4M",
        "cellView": "form"
      },
      "source": [
        "#@markdown ## What is True about what I did?\n",
        "#@markdown ### I had fun.\n",
        "cb00 = True #@param {type:'boolean'}\n",
        "#@markdown ### I learned something new.\n",
        "cb01 = True #@param {type:'boolean'}\n",
        "#@markdown ### I achieved something meaningful, or something I can build upon at a later time.\n",
        "cb02 = True #@param {type:'boolean'}\n",
        "#@markdown ## What is True about my report?\n",
        "#@markdown ### I wrote a sufficient number of well-written sentences.\n",
        "cb03 = True #@param {type:'boolean'}\n",
        "#@markdown ### My report is free of mechanical infelicities.\n",
        "cb04 = True #@param {type:'boolean'}\n",
        "#@markdown ### I used Grammarly (or something better described in my report) to check for MIs.\n",
        "cb05 = True #@param {type:'boolean'}\n",
        "#@markdown ### I reported on any connections I found between these problems and something I already know. \n",
        "cb06 = True #@param {type:'boolean'}\n",
        "#@markdown ### I reported who were and what contribution each of my collaborators made.\n",
        "cb07 = True #@param {type:'boolean'}\n",
        "#@markdown ## What is True about my calculations?\n",
        "#@markdown ### I correctly calculated the number of times each gap size occurs. \n",
        "cb08 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the number of bits per gap size with a fixed encoding.\n",
        "cb09 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the total number of bits encoded with the Huffman encoding.\n",
        "cb10 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the total number of bits encoded with the fixed encoding.\n",
        "cb11 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the compression ratio from this fixed encoding.\n",
        "cb12 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the size of the first ten million primes encoded as 32-bit integer binary data.\n",
        "cb13 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the compression ratio from the binary size.\n",
        "cb14 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the size of the first ten million primes encoded as ASCII data.\n",
        "cb15 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the compression ratio from the ASCII size (just the primes, nothing else).\n",
        "cb16 = True #@param {type:'boolean'}"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}